{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shariar076/notebook-snapshots/blob/main/RAG_chat_inteface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-tNcI76ZE3rL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install gradio\n",
        "! pip install faiss-gpu\n",
        "! pip install git+https://github.com/csebuetnlp/normalizer\n",
        "! pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qynA4EKAHmPS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdC-6gETFmTq"
      },
      "outputs": [],
      "source": [
        "import huggingface_hub\n",
        "huggingface_hub.login('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehjF95T8HHLU"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import torch\n",
        "from typing import List, Tuple\n",
        "import time\n",
        "import pandas as pd\n",
        "import faiss\n",
        "from normalizer import normalize\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSeq2SeqLM, BitsAndBytesConfig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuEulO41lapK"
      },
      "outputs": [],
      "source": [
        "class Retriever:\n",
        "  def __init__(self, doc_path, doc_col):\n",
        "    df = pd.read_csv(doc_path, sep='\\t')\n",
        "    self.document_df = pd.DataFrame()\n",
        "    self.document_df['doc'] =  df[doc_col]\n",
        "    self.document_df = self.document_df[self.document_df['doc'].str.len() > 0]\n",
        "    self.embedding_model = SentenceTransformer(\"thenlper/gte-large\")\n",
        "    self.bn_mt_model = AutoModelForSeq2SeqLM.from_pretrained(\"csebuetnlp/banglat5_nmt_en_bn\")\n",
        "    self.bn_mt_tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglat5_nmt_en_bn\", use_fast=False)\n",
        "    self.en_mt_model = AutoModelForSeq2SeqLM.from_pretrained(\"csebuetnlp/banglat5_nmt_bn_en\")\n",
        "    self.en_mt_tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglat5_nmt_bn_en\", use_fast=False)\n",
        "\n",
        "\n",
        "  def update_embeddings(self):\n",
        "    docs = self.document_df['doc'].to_numpy()\n",
        "    embeddings = self.embedding_model.encode(docs)\n",
        "    dimension = embeddings.shape[1]\n",
        "    self.index = faiss.IndexFlatL2(dimension)\n",
        "    self.index.add(embeddings)\n",
        "\n",
        "  def vector_index_search(self, user_query, k):\n",
        "    query_embedding = self.embedding_model.encode([user_query])\n",
        "    D, I = self.index.search(query_embedding, k)\n",
        "    return self.document_df.iloc[I[0]].values\n",
        "\n",
        "\n",
        "  def get_en2bn_text(self, en_text):\n",
        "      input_ids = self.bn_mt_tokenizer(normalize(en_text), return_tensors=\"pt\").input_ids\n",
        "      generated_tokens = self.bn_mt_model.generate(input_ids)\n",
        "      decoded_tokens = self.bn_mt_tokenizer.batch_decode(generated_tokens)[0].replace(\"<pad>\", \"\").replace(\"</s>\", \"\").strip()\n",
        "      return decoded_tokens\n",
        "\n",
        "  def get_bn2en_text(self, bn_text):\n",
        "      input_ids = self.en_mt_tokenizer(normalize(bn_text), return_tensors=\"pt\").input_ids\n",
        "      generated_tokens = self.en_mt_model.generate(input_ids)\n",
        "      decoded_tokens = self.en_mt_tokenizer.batch_decode(generated_tokens)[0].replace(\"<pad>\", \"\").replace(\"</s>\", \"\").strip()\n",
        "      return decoded_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RrDQQBcTHI0f"
      },
      "outputs": [],
      "source": [
        "class LlmChatBot:\n",
        "    def __init__(self, model_name: str = \"meta-llama/Llama-2-7b-chat-hf\"):\n",
        "        \"\"\"\n",
        "        Initialize the Llama 2 chatbot.\n",
        "\n",
        "        Args:\n",
        "            model_name (str): Name or path of the Llama 2 model to use\n",
        "        \"\"\"\n",
        "        print(\"Loading model and tokenizer...\")\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            # load_in_8bit=use_8_bit,\n",
        "            bnb_4bit_quant_type=\"nf4\",\n",
        "            bnb_4bit_compute_dtype=getattr(torch, \"bfloat16\"),\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "        )\n",
        "\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            quantization_config=bnb_config,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.float16,\n",
        "        )\n",
        "\n",
        "        # Set default parameters\n",
        "        self.max_length = 2048\n",
        "        self.temperature = 0.7\n",
        "        self.top_p = 0.95\n",
        "        # retriever\n",
        "        self.doc_retriever = Retriever(\"/content/vat_qna_dataset.tsv\", \"answer_en\")\n",
        "        self.doc_retriever.update_embeddings()\n",
        "        # System prompt template\n",
        "        self.system_prompt_full = (\"You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.\"\n",
        "                                  \"If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct.\"\n",
        "                                  \"If you don't know the answer to a question, please don't share false information.\"\n",
        "                                  \"Please use the provided context to answer questions. If you need to refer to the context use proper quotation.\")\n",
        "        self.system_prompt_partial = \"Please continue the conversation using the provided contexts. If you need to refer to the context use proper quotation..\"\n",
        "    def build_prompt(self, messages: List[Tuple[str, str]], context: List[str] = None) -> str:\n",
        "        \"\"\"\n",
        "        Build the prompt from conversation history and context documents.\n",
        "\n",
        "        Args:\n",
        "            messages (List[Tuple[str, str]]): List of (role, content) tuples\n",
        "            context (List[str], optional): List of relevant context passages\n",
        "\n",
        "        Returns:\n",
        "            str: Formatted prompt for the model\n",
        "        \"\"\"\n",
        "\n",
        "        if len(messages) == 1:\n",
        "          prompt = f\"<s>[INST] <<SYS>>\\n{self.system_prompt_full}\\n<</SYS>>\\n\\n\"\n",
        "        else:\n",
        "          prompt = f\"<s>[INST] <<SYS>>\\n{self.system_prompt_partial}\\n<</SYS>>\\n\\n\"\n",
        "\n",
        "        # Add context if provided\n",
        "        if context is not None and len(context) > 0:\n",
        "            prompt += \"Here is some relevant context to help answer the question:\\n\\n\"\n",
        "            for i, doc in enumerate(context, 1):\n",
        "                prompt += f\"Context {i}:\\n{doc[0].strip()}\\n\\n\"\n",
        "            prompt += \"Please use this context to provide an informed answer.\\n\\n\"\n",
        "\n",
        "        for i, (role, content) in enumerate(messages):\n",
        "            if role == \"user\":\n",
        "                prompt += f\"{self.doc_retriever.get_bn2en_text(content) if not self.is_english(content) else content} [/INST] \"\n",
        "            else:  # assistant\n",
        "                prompt += f\"{self.doc_retriever.get_bn2en_text(content) if not self.is_english(content) else content} </s><s>[INST] \"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def is_english(self, text):\n",
        "        english_pattern = r'^[a-zA-Z0-9\\s.,!?\\'\"()-]+$'\n",
        "        return bool(re.match(english_pattern, text))\n",
        "\n",
        "\n",
        "    def generate_response(\n",
        "        self,\n",
        "        message: str,\n",
        "        history: List[Tuple[str, str]],\n",
        "        # docs: List[str] = None\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Generate a response for the given message, conversation history, and context documents.\n",
        "\n",
        "        Args:\n",
        "            message (str): Current user message\n",
        "            history (List[Tuple[str, str]]): Previous conversation history\n",
        "            docs (List[str], optional): List of relevant context documents\n",
        "\n",
        "        Returns:\n",
        "            str: Model's response\n",
        "        \"\"\"\n",
        "        # Convert history to list of (role, content) tuples\n",
        "        message_en = self.doc_retriever.get_bn2en_text(message) if not self.is_english(message) else message\n",
        "        messages = []\n",
        "        for user_msg, assistant_msg in history[-2:]:\n",
        "            messages.extend([(\"user\", user_msg), (\"assistant\", assistant_msg)])\n",
        "        messages.append((\"user\", message_en))\n",
        "\n",
        "        docs = self.doc_retriever.vector_index_search(message_en, k=3)\n",
        "        print(\"=\"*100)\n",
        "        print(docs)\n",
        "        print(\"=\"*100)\n",
        "        # Build the prompt with context\n",
        "        prompt = self.build_prompt(messages, context=docs)\n",
        "        print(\"=\"*100)\n",
        "        print(prompt)\n",
        "        print(\"=\"*100)\n",
        "        # Tokenize input\n",
        "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(self.model.device)\n",
        "\n",
        "        # Generate response\n",
        "        with torch.inference_mode():\n",
        "            outputs = self.model.generate(\n",
        "                inputs[\"input_ids\"],\n",
        "                attention_mask=inputs[\"attention_mask\"],\n",
        "                max_length=self.max_length,\n",
        "                temperature=self.temperature,\n",
        "                top_p=self.top_p,\n",
        "                do_sample=True,\n",
        "                pad_token_id=self.tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Decode and clean response\n",
        "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        response = response.split('[/INST]')[-1].strip()\n",
        "        response = self.doc_retriever.get_en2bn_text(response) if not self.is_english(message) else response\n",
        "        return response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ed21ce471b37439aac927514ff28a428",
            "9a5fbf071b0c41f09fa24f0bad271b6b",
            "e3304a7630714a3993e63e1b01c42bdd",
            "33380cf0ec194c20a84db98106af0c1e",
            "96df2e43d7c9445498e9277ef2d883c5",
            "8f46a8006a3b46d2929f1620a6b5f995",
            "41e121a55a454ec8842fb382bf5af1a3",
            "b231e6afaee545e085ce42db24460e14",
            "08059a650785467a92646403328320b2",
            "7f85636e82d5458d9eb6cfda0a734e9e",
            "db9463e8e2114767a3fc60814aeaad94"
          ]
        },
        "id": "l0C03kZZA8tH",
        "outputId": "4f0f220b-a58c-4c96-edab-1de1e72545a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model and tokenizer...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed21ce471b37439aac927514ff28a428"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "/usr/local/lib/python3.10/dist-packages/gradio/components/chatbot.py:231: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://1f12fafbf9e7f0eed8.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1f12fafbf9e7f0eed8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "[['The Value Added Tax was introduced in Bangladesh on 1 July 1991. The new law on VAT will come into force with effect from 1 July 2017.']\n",
            " ['The rates of Tax applicable in Bangladesh are as follows:\\n\\nThe standard rate of VAT in Bangladesh is 15%.\\nExport 0%.\\nTurnover Tax applicable to turnover tax payer up to Taka 8 million is 3% (VAT is not applicable to them).\\nSupplementary Duty at different rates on luxury goods and various services.\\nNo other lower rates.']\n",
            " ['There is no geographical limitation for registration under the VAT law. Under the new procedure, no Trade Licence or any such document shall also be required for obtaining registration. Registration will be granted on the basis of Postal Codes. Therefore, registration can be obtained from any place in Bangladesh.']]\n",
            "====================================================================================================\n",
            "====================================================================================================\n",
            "<s>[INST] <<SYS>>\n",
            "You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct.If you don't know the answer to a question, please don't share false information.Please use the provided context to answer questions. If you need to refer to the context use proper quotation.\n",
            "<</SYS>>\n",
            "\n",
            "Here is some relevant context to help answer the question:\n",
            "\n",
            "Context 1:\n",
            "The Value Added Tax was introduced in Bangladesh on 1 July 1991. The new law on VAT will come into force with effect from 1 July 2017.\n",
            "\n",
            "Context 2:\n",
            "The rates of Tax applicable in Bangladesh are as follows:\n",
            "\n",
            "The standard rate of VAT in Bangladesh is 15%.\n",
            "Export 0%.\n",
            "Turnover Tax applicable to turnover tax payer up to Taka 8 million is 3% (VAT is not applicable to them).\n",
            "Supplementary Duty at different rates on luxury goods and various services.\n",
            "No other lower rates.\n",
            "\n",
            "Context 3:\n",
            "There is no geographical limitation for registration under the VAT law. Under the new procedure, no Trade Licence or any such document shall also be required for obtaining registration. Registration will be granted on the basis of Postal Codes. Therefore, registration can be obtained from any place in Bangladesh.\n",
            "\n",
            "Please use this context to provide an informed answer.\n",
            "\n",
            "When was VAT introduced in Bangladesh? [/INST] \n",
            "====================================================================================================\n",
            "====================================================================================================\n",
            "[['If any goods or service stipulated in the First Schedule of the law falls under the purview of your economic activities, in that case, according to law, no obligation of VAT shall accrue in your business.\\nMoreover, the annual turnover of your business shall determine applicability of VAT in the business. (See Question- 2.2). But without regard to the annual turnover of your business, you can pay VAT after VAT registration, if you so desire.']\n",
            " ['VAT is levied on all taxable imports and taxable supplies.']\n",
            " ['No documents other than the Tax Payer’s Return (Form VAT-9.1 or 9.2) and purchase-sale information (Form VAT-6.20) are required to be sent to the VAT office.']]\n",
            "====================================================================================================\n",
            "====================================================================================================\n",
            "<s>[INST] <<SYS>>\n",
            "Please continue the conversation using the provided contexts. If you need to refer to the context use proper quotation..\n",
            "<</SYS>>\n",
            "\n",
            "Here is some relevant context to help answer the question:\n",
            "\n",
            "Context 1:\n",
            "If any goods or service stipulated in the First Schedule of the law falls under the purview of your economic activities, in that case, according to law, no obligation of VAT shall accrue in your business.\n",
            "Moreover, the annual turnover of your business shall determine applicability of VAT in the business. (See Question- 2.2). But without regard to the annual turnover of your business, you can pay VAT after VAT registration, if you so desire.\n",
            "\n",
            "Context 2:\n",
            "VAT is levied on all taxable imports and taxable supplies.\n",
            "\n",
            "Context 3:\n",
            "No documents other than the Tax Payer’s Return (Form VAT-9.1 or 9.2) and purchase-sale information (Form VAT-6.20) are required to be sent to the VAT office.\n",
            "\n",
            "Please use this context to provide an informed answer.\n",
            "\n",
            "When was VAT introduced in Bangladesh? [/INST] VAT (Value Added Tax) was introduced in Bangladesh on 1 July 1991 and the new VAT Act will come into force on 1 July 2017. </s><s>[INST] So do I need to pay VAT? [/INST] \n",
            "====================================================================================================\n",
            "====================================================================================================\n",
            "[['No.']\n",
            " ['The Supplementary Duty shall be levied-\\n\\n\\xa0In case of import on which Supplementary Duty is imposable; an\\nThe supplier of service shall pay the Supplementary Duty in case of supply of goods manufactured in Bangladesh on which Supplementary Duty is imposable or in case of supply of service on which Supplementary Duty is imposable.']\n",
            " ['According to Section 55 of the Value Added Tax and Supplementary Duty Act, 2012-\\n\\nOn import of supplementary duty-imposed products\\nOn supply of supplementary duty-imposed products prepared in Bangladesh;\\nTax surplus duty imposed on supply of supplementary taxable services to Bangladesh\\n\\nAdult supplements are generally applicable for the goods or services that are generally meant for luxury or discouragement.']]\n",
            "====================================================================================================\n",
            "====================================================================================================\n",
            "<s>[INST] <<SYS>>\n",
            "Please continue the conversation using the provided contexts. If you need to refer to the context use proper quotation..\n",
            "<</SYS>>\n",
            "\n",
            "Here is some relevant context to help answer the question:\n",
            "\n",
            "Context 1:\n",
            "No.\n",
            "\n",
            "Context 2:\n",
            "The Supplementary Duty shall be levied-\n",
            "\n",
            " In case of import on which Supplementary Duty is imposable; an\n",
            "The supplier of service shall pay the Supplementary Duty in case of supply of goods manufactured in Bangladesh on which Supplementary Duty is imposable or in case of supply of service on which Supplementary Duty is imposable.\n",
            "\n",
            "Context 3:\n",
            "According to Section 55 of the Value Added Tax and Supplementary Duty Act, 2012-\n",
            "\n",
            "On import of supplementary duty-imposed products\n",
            "On supply of supplementary duty-imposed products prepared in Bangladesh;\n",
            "Tax surplus duty imposed on supply of supplementary taxable services to Bangladesh\n",
            "\n",
            "Adult supplements are generally applicable for the goods or services that are generally meant for luxury or discouragement.\n",
            "\n",
            "Please use this context to provide an informed answer.\n",
            "\n",
            "When was VAT introduced in Bangladesh? [/INST] VAT (Value Added Tax) was introduced in Bangladesh on 1 July 1991 and the new VAT Act will come into force on 1 July 2017. </s><s>[INST] So do I need to pay VAT? [/INST] Based on the context provided, it appears that the introduction of VAT (Value Added Tax) in Bangladesh was on July 1, 1991. Therefore, if your business falls under the purview of the VAT law, you may be required to pay VAT.\n",
            "\n",
            "The applicability of VAT in your business depends on the annual turnover of your business. As per Context 1, if your business's annual turnover is below Tk. 50 lakhs, you are not required to register for VAT. However, you can still pay VAT voluntarily if you so desire.\n",
            "\n",
            "On the other hand, if your business's annual turnover is above Tk. 50 lakhs, you are required to register for VAT and pay VAT on taxable goods or services supplied.\n",
            "\n",
            "Therefore, to determine whether you need to pay VAT, you need to calculate your business's annual turnover and check if it falls below or above the threshold of Tk. 50 lakhs. If it does, you will need to register for VAT and start paying VAT on taxable goods or services supplied.\n",
            "\n",
            "It is important to note that the VAT law and regulations in Bangladesh are subject to change, so it is always best to consult with a tax professional or the VAT authority to get the most up-to-date and accurate information. </s><s>[INST] So [/INST] \n",
            "====================================================================================================\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 0.0.0.0:7860 <> https://1f12fafbf9e7f0eed8.gradio.live\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'TupleNoPrint' object has no attribute 'launch'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-84f6c4cf3913>\u001b[0m in \u001b[0;36m<cell line: 66>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-84f6c4cf3913>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mserver_port\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7860\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mdebug\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     ).launch(share=True)\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TupleNoPrint' object has no attribute 'launch'"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "def create_chat_interface(model_name) -> gr.Interface:\n",
        "    \"\"\"\n",
        "    Create and configure the Gradio chat interface.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): Name or path of the Llama 2 model to use\n",
        "\n",
        "    Returns:\n",
        "        gr.Interface: Configured Gradio interface\n",
        "    \"\"\"\n",
        "    # Initialize chatbot\n",
        "    chatbot = LlmChatBot(model_name)\n",
        "\n",
        "    # Custom CSS for better appearance\n",
        "    custom_css = \"\"\"\n",
        "    .message.user{\n",
        "        background-color: #2563eb !important;\n",
        "        color: white !important;\n",
        "        border-radius: 15px !important;\n",
        "        padding: 15px !important;\n",
        "        margin: 10px 0 !important;\n",
        "    }\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Create the interface\n",
        "    interface = gr.ChatInterface(\n",
        "        fn=chatbot.generate_response,\n",
        "        title=\"Llama 2 Chat\",\n",
        "        description=\"Chat with Llama 2 - A powerful language model by Meta\",\n",
        "        theme=gr.themes.Soft(),\n",
        "        examples=[\n",
        "            [\"কে ভ্যাট দেয়?\"],\n",
        "            [\"বাংলাদেশে মূসক কবে থেকে চালু হয়েছে?\"],\n",
        "            [\"আমি কেন ভ্যাট দেব?\"]\n",
        "        ],\n",
        "        # retry_btn=None,\n",
        "        # undo_btn=\"🔄 Undo\",\n",
        "        # clear_btn=\"🗑️ Clear\",\n",
        "    )\n",
        "\n",
        "    # Add custom CSS\n",
        "    interface.css = custom_css\n",
        "\n",
        "    return interface\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the chat server.\"\"\"\n",
        "    # Create and launch the interface\n",
        "    model_name: str = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "    # model_name: str = \"google/gemma-2-2b-it\"\n",
        "    interface = create_chat_interface(model_name)\n",
        "\n",
        "    # Launch with share=True to get a public URL\n",
        "    interface.launch(\n",
        "        share=True,\n",
        "        server_name=\"0.0.0.0\",\n",
        "        server_port=7860,\n",
        "        debug=True\n",
        "    ).launch(share=True)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def is_english(text):\n",
        "    english_pattern = r'^[a-zA-Z0-9\\s.,!?\\'\"()-]+$'\n",
        "    return bool(re.match(english_pattern, text))\n",
        "\n",
        "is_english(\"who?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVvx76zWcGSj",
        "outputId": "50cd2914-b6dd-4a90-d93e-b966fc9df427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ed21ce471b37439aac927514ff28a428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a5fbf071b0c41f09fa24f0bad271b6b",
              "IPY_MODEL_e3304a7630714a3993e63e1b01c42bdd",
              "IPY_MODEL_33380cf0ec194c20a84db98106af0c1e"
            ],
            "layout": "IPY_MODEL_96df2e43d7c9445498e9277ef2d883c5"
          }
        },
        "9a5fbf071b0c41f09fa24f0bad271b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f46a8006a3b46d2929f1620a6b5f995",
            "placeholder": "​",
            "style": "IPY_MODEL_41e121a55a454ec8842fb382bf5af1a3",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "e3304a7630714a3993e63e1b01c42bdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b231e6afaee545e085ce42db24460e14",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08059a650785467a92646403328320b2",
            "value": 2
          }
        },
        "33380cf0ec194c20a84db98106af0c1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f85636e82d5458d9eb6cfda0a734e9e",
            "placeholder": "​",
            "style": "IPY_MODEL_db9463e8e2114767a3fc60814aeaad94",
            "value": " 2/2 [01:14&lt;00:00, 34.13s/it]"
          }
        },
        "96df2e43d7c9445498e9277ef2d883c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f46a8006a3b46d2929f1620a6b5f995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41e121a55a454ec8842fb382bf5af1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b231e6afaee545e085ce42db24460e14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08059a650785467a92646403328320b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f85636e82d5458d9eb6cfda0a734e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db9463e8e2114767a3fc60814aeaad94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}